{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IS14Kadai2_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdmkQ5hdqFPL"
      },
      "source": [
        "#**Week 14 Assignment2** \n",
        "  \n",
        "Name: Tianrungroj Yossathorn\n",
        "  \n",
        "Student ID: 03200437"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wss6pHYbg1Bh"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zddD47nfa6bl"
      },
      "source": [
        "## Data Preparation\n",
        "Using data from Penntree bank just the same as week10's assignment. Previously implemented data preparation is being modified so that words and part of speeches are in integer label encoding.  \n",
        "  \n",
        "Summary:\n",
        "\n",
        "- Train data size: 1460 sentences\n",
        "- Test data size: 273 sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-DbamUpmbh5"
      },
      "source": [
        "### PennTree bank data preparation\n",
        "  using previously implemented class in Viterbi algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzjNdwGIa6Jw"
      },
      "source": [
        "# pos: part of speech\n",
        "class PennTree:\n",
        "    def __init__(self, filenames=None, train_ratio=0.8):\n",
        "        self.train_ratio=train_ratio\n",
        "        self.pos2idx={'PAD': 0, 'BOS': 0}\n",
        "        self.idx2pos=['PAD', 'BOS']\n",
        "        self.word2idx={'PAD':0, 'UNK': 1, 'NUM': 2}\n",
        "        self.idx2word=['PAD', 'UNK', 'NUM']\n",
        "        self.wordCount={}\n",
        "        self.prob_pos2pos=None\n",
        "        self.prob_pos2word=None\n",
        "        self.train_data=[]\n",
        "        self.test_data=[]\n",
        "        self.train_x=[]\n",
        "        self.train_y=[]\n",
        "        self.test_x=[]\n",
        "        self.test_y=[]\n",
        "        random.shuffle(filenames)\n",
        "        self.initTable(filenames)\n",
        "        self.num_word=len(self.idx2word)\n",
        "        self.num_pos=len(self.idx2pos)\n",
        "        #self.prepOnehot()\n",
        "        \n",
        "        \n",
        "    def getSentences(self, filename):\n",
        "        with open(filename, 'r') as file:\n",
        "            lines=[l for l in file.readlines()]\n",
        "        sentence=\"\"\n",
        "        sentences=[]\n",
        "        chkNewSentence=True\n",
        "        for i in range(len(lines)):\n",
        "            if i+1<len(lines) and (('===' in lines[i]) or (lines[i]=='\\n' and lines[i+1]=='\\n')):\n",
        "                if len(sentence)>1:\n",
        "                    sentences.append(sentence)\n",
        "                    sentence=\"\"\n",
        "            elif lines[i]=='\\n':\n",
        "                continue\n",
        "            else:\n",
        "                tmpstr=lines[i]\n",
        "                if tmpstr[0]=='[':\n",
        "                    tmpstr=tmpstr[2:] # rm space too\n",
        "                if tmpstr[-1]=='\\n':\n",
        "                    tmpstr=tmpstr[:-1]\n",
        "                if tmpstr[-1]==']':\n",
        "                    tmpstr=tmpstr[:-2] # rm space too\n",
        "                sentence=sentence+str(tmpstr)+' '\n",
        "        if len(sentence)>1:\n",
        "                    sentences.append(sentence)\n",
        "                    sentence=\"\"\n",
        "        return sentences\n",
        "    \n",
        "    def initTable(self, filenames):\n",
        "        num_train_file=int(self.train_ratio*len(filenames))\n",
        "        for filename in filenames:\n",
        "            sentences=self.getSentences(filename)\n",
        "            for sentence in sentences:\n",
        "                poses=self.extractPos(sentence)\n",
        "                if num_train_file<=0:\n",
        "                    self.test_data.append(np.array(poses))\n",
        "                    continue\n",
        "                else:\n",
        "                    self.train_data.append(np.array(poses))\n",
        "                for word, pos in poses:\n",
        "                    if not word in self.wordCount:\n",
        "                        self.wordCount[word]=1\n",
        "                    else:\n",
        "                        self.wordCount[word]+=1\n",
        "                    if not pos in self.pos2idx:\n",
        "                        self.pos2idx[pos]=len(self.idx2pos)\n",
        "                        self.idx2pos.append(pos)\n",
        "            num_train_file-=1\n",
        "            \n",
        "        for word in self.wordCount:\n",
        "            count = self.wordCount[word]\n",
        "            if count==1:\n",
        "                continue\n",
        "            self.word2idx[word]=len(self.idx2word)\n",
        "            self.idx2word.append(word)\n",
        "        self.prob_pos2pos=np.zeros([len(self.idx2pos), len(self.idx2pos)])\n",
        "        self.prob_pos2word=np.zeros([len(self.idx2word), len(self.idx2word)])\n",
        "        \n",
        "\n",
        "    def extractPos(self, sentence):\n",
        "        poses=[]\n",
        "        words=sentence.split(' ')\n",
        "        words=[w for w in words if not w=='']\n",
        "        for word in words:\n",
        "            if not '/' in word:\n",
        "                continue\n",
        "            i=-1\n",
        "            while word[i]!='/':\n",
        "                i-=1\n",
        "            pos=word[i+1:]\n",
        "            w=word[:i].lower()\n",
        "            w=self.convertIfFloat(w)\n",
        "            poses.append((w,pos))\n",
        "        return poses\n",
        "            \n",
        "    def convertIfFloat(self,w):\n",
        "        try:\n",
        "            tmp=float(w)\n",
        "            w='NUM'\n",
        "        except:\n",
        "            assert(1==1)\n",
        "        return w\n",
        "    \n",
        "    def convertIfUNK(self, word):\n",
        "        if not word in self.idx2word:\n",
        "            w='UNK'\n",
        "        else:\n",
        "            w=word\n",
        "        return w\n",
        "    \n",
        "    def train(self):\n",
        "        print(f\"Training with {str(len(self.train_data))} sentences.\")\n",
        "        start_time=time.time()\n",
        "        for poses in self.train_data:\n",
        "            prev_pos='BOS'\n",
        "            for word, cur_pos in poses:\n",
        "                w=self.convertIfUNK(word)\n",
        "                self.prob_pos2pos[self.pos2idx[prev_pos]][self.pos2idx[cur_pos]]+=1\n",
        "                self.prob_pos2word[self.pos2idx[cur_pos]][self.word2idx[w]]+=1\n",
        "                prev_pos=cur_pos\n",
        "\n",
        "        \n",
        "        a=self.prob_pos2pos\n",
        "        self.prob_pos2pos=a/(np.sum(a, axis=1).reshape((a.shape[0],1))+1e-15)\n",
        "        a=self.prob_pos2word\n",
        "        self.prob_pos2word=a/(np.sum(a, axis=1).reshape((a.shape[0],1))+1e-15)\n",
        "        elapsed_time=time.time()-start_time\n",
        "        print(f\"Elapsed time {str(elapsed_time)}s\")\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZ8XBiUhEXU"
      },
      "source": [
        "random.seed(1234)\n",
        "filenames=['/content/drive/MyDrive/UTokyo/3A/IntelligenceSystem/treebank/tagged/wsj_'+str(i).zfill(4)+'.pos' for i in range(1,200)]\n",
        "P = PennTree(filenames=filenames,train_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gpRBq_amvs5"
      },
      "source": [
        "### Integer Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHcnwvh203q6"
      },
      "source": [
        "train_x, train_y, test_x, test_y=[], [], [], []\n",
        "for s in P.train_data:\n",
        "  sentence, pos = zip(*s)\n",
        "  train_x.append([P.word2idx[P.convertIfUNK(w)] for w in sentence])\n",
        "  train_y.append([P.pos2idx[p] for p in pos])\n",
        "for s in P.test_data:\n",
        "  sentence, pos = zip(*s)\n",
        "  test_x.append([P.word2idx[P.convertIfUNK(w)] for w in sentence])\n",
        "  test_y.append([P.pos2idx[p] for p in pos])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUkekjbd45C9",
        "outputId": "ac99ccec-b2a0-48f1-c0bf-af637ef2b410"
      },
      "source": [
        "MAX_LEN = len(max(train_x, key=len))\n",
        "MAX_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "430"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKiTTKrqsXAa"
      },
      "source": [
        "# padding the sentences so they have the same length which is required before feeding into the keras' RNN model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_x = pad_sequences(train_x, maxlen=MAX_LEN, padding='post')\n",
        "train_y = pad_sequences(train_y, maxlen=MAX_LEN, padding='post')\n",
        "test_x = pad_sequences(test_x, maxlen=MAX_LEN, padding='post')\n",
        "test_y = pad_sequences(test_y, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3yCDlQk9VJL"
      },
      "source": [
        "### Onehot converter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1YANU0E9USL"
      },
      "source": [
        "def to_onehot(sequences, categories):\n",
        "  onehot_sequences = []\n",
        "  for s in sequences:\n",
        "    a=np.array(s)\n",
        "    tmp = np.zeros((a.size, categories))\n",
        "    tmp[np.arange(a.size),a] = 1\n",
        "    onehot_sequences.append(tmp)\n",
        "  # print(onehot_sequences[0])\n",
        "  return np.array(onehot_sequences)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rVwbtqL6JHz"
      },
      "source": [
        "## RNN model implementation training and discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ_LsD8E6W3I"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULeWNzcAaN4S"
      },
      "source": [
        "### Approach 1\n",
        "- Normal LSTM\n",
        "- Integer Label Encoding for words\n",
        "- padding with 'PAD': 0\n",
        "  \n",
        "Test accuracy: 90.74%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo7JwC4YfrkF",
        "outputId": "4f9ed37d-8924-4a14-def0-ea7da8566f5b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(P.idx2word), output_dim=64))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(P.idx2pos))))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          296384    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 128)         98816     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 48)          6192      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, None, 48)          0         \n",
            "=================================================================\n",
            "Total params: 401,392\n",
            "Trainable params: 401,392\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1dHqW4B8nbl"
      },
      "source": [
        "train_y_oh=to_onehot(train_y, len(P.pos2idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgOpBI-oA31x",
        "outputId": "54e015f9-32d9-4f4a-eee3-1b31f6424aa3"
      },
      "source": [
        "model.fit(train_x, train_y_oh, batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "11/11 [==============================] - 20s 2s/step - loss: 3.6117 - accuracy: 0.6489 - val_loss: 0.8308 - val_accuracy: 0.8769\n",
            "Epoch 2/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.7874 - accuracy: 0.8744 - val_loss: 0.7827 - val_accuracy: 0.8769\n",
            "Epoch 3/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.7695 - accuracy: 0.8732 - val_loss: 0.7233 - val_accuracy: 0.8633\n",
            "Epoch 4/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.7102 - accuracy: 0.8647 - val_loss: 0.6485 - val_accuracy: 0.8770\n",
            "Epoch 5/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.6385 - accuracy: 0.8764 - val_loss: 0.5800 - val_accuracy: 0.8799\n",
            "Epoch 6/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.6063 - accuracy: 0.8699 - val_loss: 0.5240 - val_accuracy: 0.8876\n",
            "Epoch 7/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.5296 - accuracy: 0.8852 - val_loss: 0.5005 - val_accuracy: 0.8842\n",
            "Epoch 8/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.5148 - accuracy: 0.8801 - val_loss: 0.4922 - val_accuracy: 0.8817\n",
            "Epoch 9/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.5064 - accuracy: 0.8788 - val_loss: 0.4852 - val_accuracy: 0.8803\n",
            "Epoch 10/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.5064 - accuracy: 0.8750 - val_loss: 0.4802 - val_accuracy: 0.8798\n",
            "Epoch 11/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.5078 - accuracy: 0.8733 - val_loss: 0.4727 - val_accuracy: 0.8798\n",
            "Epoch 12/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4944 - accuracy: 0.8720 - val_loss: 0.4501 - val_accuracy: 0.8787\n",
            "Epoch 13/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.4618 - accuracy: 0.8779 - val_loss: 0.5020 - val_accuracy: 0.8780\n",
            "Epoch 14/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.4790 - accuracy: 0.8786 - val_loss: 0.4578 - val_accuracy: 0.8902\n",
            "Epoch 15/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4668 - accuracy: 0.8875 - val_loss: 0.4315 - val_accuracy: 0.8904\n",
            "Epoch 16/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4409 - accuracy: 0.8867 - val_loss: 0.4127 - val_accuracy: 0.8887\n",
            "Epoch 17/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4283 - accuracy: 0.8843 - val_loss: 0.4070 - val_accuracy: 0.8891\n",
            "Epoch 18/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4131 - accuracy: 0.8882 - val_loss: 0.4019 - val_accuracy: 0.8909\n",
            "Epoch 19/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4105 - accuracy: 0.8893 - val_loss: 0.3985 - val_accuracy: 0.8918\n",
            "Epoch 20/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4152 - accuracy: 0.8882 - val_loss: 0.3955 - val_accuracy: 0.8926\n",
            "Epoch 21/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4036 - accuracy: 0.8911 - val_loss: 0.3929 - val_accuracy: 0.8935\n",
            "Epoch 22/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4047 - accuracy: 0.8906 - val_loss: 0.3905 - val_accuracy: 0.8937\n",
            "Epoch 23/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4058 - accuracy: 0.8900 - val_loss: 0.3882 - val_accuracy: 0.8940\n",
            "Epoch 24/40\n",
            "11/11 [==============================] - 16s 2s/step - loss: 0.4040 - accuracy: 0.8898 - val_loss: 0.3859 - val_accuracy: 0.8942\n",
            "Epoch 25/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.4075 - accuracy: 0.8887 - val_loss: 0.3838 - val_accuracy: 0.8943\n",
            "Epoch 26/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.3991 - accuracy: 0.8905 - val_loss: 0.3816 - val_accuracy: 0.8947\n",
            "Epoch 27/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3870 - accuracy: 0.8933 - val_loss: 0.3794 - val_accuracy: 0.8953\n",
            "Epoch 28/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4084 - accuracy: 0.8872 - val_loss: 0.3773 - val_accuracy: 0.8954\n",
            "Epoch 29/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3784 - accuracy: 0.8949 - val_loss: 0.3749 - val_accuracy: 0.8954\n",
            "Epoch 30/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.4117 - accuracy: 0.8857 - val_loss: 0.3732 - val_accuracy: 0.8984\n",
            "Epoch 31/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3923 - accuracy: 0.8929 - val_loss: 0.3699 - val_accuracy: 0.8997\n",
            "Epoch 32/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.3807 - accuracy: 0.8965 - val_loss: 0.3672 - val_accuracy: 0.9001\n",
            "Epoch 33/40\n",
            "11/11 [==============================] - 18s 2s/step - loss: 0.3851 - accuracy: 0.8952 - val_loss: 0.3644 - val_accuracy: 0.9003\n",
            "Epoch 34/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3889 - accuracy: 0.8934 - val_loss: 0.3616 - val_accuracy: 0.9004\n",
            "Epoch 35/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3703 - accuracy: 0.8981 - val_loss: 0.3587 - val_accuracy: 0.9006\n",
            "Epoch 36/40\n",
            "11/11 [==============================] - 16s 2s/step - loss: 0.3718 - accuracy: 0.8973 - val_loss: 0.3557 - val_accuracy: 0.9011\n",
            "Epoch 37/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3753 - accuracy: 0.8957 - val_loss: 0.3528 - val_accuracy: 0.9016\n",
            "Epoch 38/40\n",
            "11/11 [==============================] - 16s 2s/step - loss: 0.3668 - accuracy: 0.8979 - val_loss: 0.3497 - val_accuracy: 0.9023\n",
            "Epoch 39/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3543 - accuracy: 0.9013 - val_loss: 0.3464 - val_accuracy: 0.9045\n",
            "Epoch 40/40\n",
            "11/11 [==============================] - 17s 2s/step - loss: 0.3576 - accuracy: 0.9026 - val_loss: 0.3429 - val_accuracy: 0.9064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf70725898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfVxporlBa84",
        "outputId": "bc81645f-b5af-48c8-d6fc-097c80b3990e"
      },
      "source": [
        "scores = model.evaluate(test_x, to_onehot(test_y, len(P.pos2idx)))\n",
        "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 119ms/step - loss: 0.3384 - accuracy: 0.9074\n",
            "accuracy: 90.73600769042969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xY2ovuKC4dD"
      },
      "source": [
        "### Approach2\n",
        "I read some articles and they used bidirectional LSTM so I tried using it.\n",
        "- Bidirectional LSTM\n",
        "- Integer Label Encoding for words\n",
        "- padding with 'PAD':0\n",
        "  \n",
        "Test accuracy: 94.30%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZf9ueOJENKq",
        "outputId": "d1723bac-a848-4f02-8d6a-823c7ce90951"
      },
      "source": [
        "model2 = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LEN, )))\n",
        "model2.add(Embedding(input_dim=len(P.idx2word), output_dim=64))\n",
        "model2.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model2.add(TimeDistributed(Dense(len(P.pos2idx))))\n",
        "model2.add(Activation('softmax'))\n",
        " \n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 64)          296384    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, None, 256)         197632    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, None, 48)          12336     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, None, 48)          0         \n",
            "=================================================================\n",
            "Total params: 506,352\n",
            "Trainable params: 506,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_nIBtFMDtNz"
      },
      "source": [
        "train_y_oh=to_onehot(train_y, len(P.pos2idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeqMXjqmEsHy",
        "outputId": "b856f1ba-7e42-4652-9ea3-9699beb11022"
      },
      "source": [
        "model2.fit(train_x, train_y_oh, batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "10/10 [==============================] - ETA: 0s - loss: 3.5788 - accuracy: 0.6159WARNING:tensorflow:5 out of the last 138 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbf658c1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "10/10 [==============================] - 29s 3s/step - loss: 3.5388 - accuracy: 0.6305 - val_loss: 0.6174 - val_accuracy: 0.8799\n",
            "Epoch 2/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.7792 - accuracy: 0.8682 - val_loss: 0.5778 - val_accuracy: 0.8799\n",
            "Epoch 3/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.5569 - accuracy: 0.8701 - val_loss: 0.4682 - val_accuracy: 0.8799\n",
            "Epoch 4/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.4810 - accuracy: 0.8718 - val_loss: 0.4163 - val_accuracy: 0.8799\n",
            "Epoch 5/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.4333 - accuracy: 0.8742 - val_loss: 0.4019 - val_accuracy: 0.8799\n",
            "Epoch 6/40\n",
            "10/10 [==============================] - 28s 3s/step - loss: 0.4371 - accuracy: 0.8714 - val_loss: 0.3928 - val_accuracy: 0.8898\n",
            "Epoch 7/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.4281 - accuracy: 0.8816 - val_loss: 0.3862 - val_accuracy: 0.8941\n",
            "Epoch 8/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.4182 - accuracy: 0.8856 - val_loss: 0.3811 - val_accuracy: 0.8953\n",
            "Epoch 9/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.4054 - accuracy: 0.8890 - val_loss: 0.3773 - val_accuracy: 0.8952\n",
            "Epoch 10/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.4073 - accuracy: 0.8867 - val_loss: 0.3831 - val_accuracy: 0.8880\n",
            "Epoch 11/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.4068 - accuracy: 0.8845 - val_loss: 0.3799 - val_accuracy: 0.8957\n",
            "Epoch 12/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.4136 - accuracy: 0.8872 - val_loss: 0.3775 - val_accuracy: 0.8958\n",
            "Epoch 13/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.4034 - accuracy: 0.8894 - val_loss: 0.3754 - val_accuracy: 0.8950\n",
            "Epoch 14/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.4011 - accuracy: 0.8889 - val_loss: 0.3734 - val_accuracy: 0.8954\n",
            "Epoch 15/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.3937 - accuracy: 0.8907 - val_loss: 0.3717 - val_accuracy: 0.8953\n",
            "Epoch 16/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3922 - accuracy: 0.8904 - val_loss: 0.3699 - val_accuracy: 0.8963\n",
            "Epoch 17/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3908 - accuracy: 0.8913 - val_loss: 0.3681 - val_accuracy: 0.8963\n",
            "Epoch 18/40\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.4003 - accuracy: 0.8880 - val_loss: 0.3670 - val_accuracy: 0.8962\n",
            "Epoch 19/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3987 - accuracy: 0.8879 - val_loss: 0.3710 - val_accuracy: 0.8958\n",
            "Epoch 20/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3865 - accuracy: 0.8906 - val_loss: 0.3713 - val_accuracy: 0.8961\n",
            "Epoch 21/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3921 - accuracy: 0.8884 - val_loss: 0.3763 - val_accuracy: 0.8960\n",
            "Epoch 22/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3913 - accuracy: 0.8879 - val_loss: 0.3727 - val_accuracy: 0.8965\n",
            "Epoch 23/40\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.3830 - accuracy: 0.8905 - val_loss: 0.3673 - val_accuracy: 0.8976\n",
            "Epoch 24/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3799 - accuracy: 0.8917 - val_loss: 0.3685 - val_accuracy: 0.8998\n",
            "Epoch 25/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3675 - accuracy: 0.8964 - val_loss: 0.3605 - val_accuracy: 0.9007\n",
            "Epoch 26/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.3668 - accuracy: 0.8967 - val_loss: 0.3516 - val_accuracy: 0.9041\n",
            "Epoch 27/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.3533 - accuracy: 0.9019 - val_loss: 0.3469 - val_accuracy: 0.9066\n",
            "Epoch 28/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.3595 - accuracy: 0.9020 - val_loss: 0.3417 - val_accuracy: 0.9106\n",
            "Epoch 29/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.3447 - accuracy: 0.9088 - val_loss: 0.3353 - val_accuracy: 0.9164\n",
            "Epoch 30/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.3478 - accuracy: 0.9121 - val_loss: 0.3260 - val_accuracy: 0.9182\n",
            "Epoch 31/40\n",
            "10/10 [==============================] - 25s 2s/step - loss: 0.3396 - accuracy: 0.9148 - val_loss: 0.3213 - val_accuracy: 0.9224\n",
            "Epoch 32/40\n",
            "10/10 [==============================] - 25s 3s/step - loss: 0.3337 - accuracy: 0.9176 - val_loss: 0.3122 - val_accuracy: 0.9242\n",
            "Epoch 33/40\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.3248 - accuracy: 0.9197 - val_loss: 0.2966 - val_accuracy: 0.9263\n",
            "Epoch 34/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3139 - accuracy: 0.9215 - val_loss: 0.2936 - val_accuracy: 0.9288\n",
            "Epoch 35/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.2921 - accuracy: 0.9278 - val_loss: 0.2780 - val_accuracy: 0.9342\n",
            "Epoch 36/40\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.2811 - accuracy: 0.9320 - val_loss: 0.2593 - val_accuracy: 0.9371\n",
            "Epoch 37/40\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.2724 - accuracy: 0.9335 - val_loss: 0.2458 - val_accuracy: 0.9387\n",
            "Epoch 38/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.2507 - accuracy: 0.9367 - val_loss: 0.2340 - val_accuracy: 0.9407\n",
            "Epoch 39/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.2441 - accuracy: 0.9373 - val_loss: 0.2298 - val_accuracy: 0.9416\n",
            "Epoch 40/40\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.2277 - accuracy: 0.9401 - val_loss: 0.2078 - val_accuracy: 0.9445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf651127f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3J0BFW4GdFj",
        "outputId": "1c1b2490-baa0-4a03-bf5c-2d971bcd86ef"
      },
      "source": [
        "scores = model2.evaluate(test_x, to_onehot(test_y, len(P.pos2idx)))\n",
        "print(f\"{model2.metrics_names[1]}: {scores[1] * 100}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 2s 190ms/step - loss: 0.2152 - accuracy: 0.9430\n",
            "accuracy: 94.29678916931152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRjM-wlwjpo8"
      },
      "source": [
        "### Discussion\n",
        "As shown in above sections, the performance of LSTM is better than the Viterbi algorithm (around 86% accuracy). The reason is that RNN structure takes context of every previous words into account in order to make a prediction, as opposed to Viterbi algorithm that based on HMM structure which considers only the adjacent state. \n",
        "   \n",
        "Moreover, bidirectional LSTM outperformed normal LSTM by almost 4% margin. The reason is that, unlike normal LSTM that considers context of previous words, bidirectional LSTM also considers context of words coming after as the structure propagates through time frames both forward and backward directions. "
      ]
    }
  ]
}