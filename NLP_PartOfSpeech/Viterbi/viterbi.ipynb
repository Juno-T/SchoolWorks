{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos: part of speech\n",
    "class Viterbi_PennTree:\n",
    "    def __init__(self, filenames=None, train_ratio=0.8):\n",
    "        self.train_ratio=train_ratio\n",
    "        self.pos2idx={'BOS': 0}\n",
    "        self.idx2pos=['BOS']\n",
    "        self.word2idx={'UNK': 0, 'NUM': 1}\n",
    "        self.idx2word=['UNK', 'NUM']\n",
    "        self.wordCount={}\n",
    "        self.prob_pos2pos=None\n",
    "        self.prob_pos2word=None\n",
    "        self.train_data=[]\n",
    "        self.test_data=[]\n",
    "        random.shuffle(filenames)\n",
    "        self.initTable(filenames)\n",
    "        self.num_word=len(self.idx2word)\n",
    "        self.num_pos=len(self.idx2pos)\n",
    "        \n",
    "        \n",
    "    def getSentences(self, filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            lines=[l for l in file.readlines()]\n",
    "        sentence=\"\"\n",
    "        sentences=[]\n",
    "        chkNewSentence=True\n",
    "        for i in range(len(lines)):\n",
    "            if i+1<len(lines) and (('===' in lines[i]) or (lines[i]=='\\n' and lines[i+1]=='\\n')):\n",
    "                if len(sentence)>1:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence=\"\"\n",
    "            elif lines[i]=='\\n':\n",
    "                continue\n",
    "            else:\n",
    "                tmpstr=lines[i]\n",
    "                if tmpstr[0]=='[':\n",
    "                    tmpstr=tmpstr[2:] # rm space too\n",
    "                if tmpstr[-1]=='\\n':\n",
    "                    tmpstr=tmpstr[:-1]\n",
    "                if tmpstr[-1]==']':\n",
    "                    tmpstr=tmpstr[:-2] # rm space too\n",
    "                sentence=sentence+str(tmpstr)+' '\n",
    "        if len(sentence)>1:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence=\"\"\n",
    "        return sentences\n",
    "    \n",
    "    def initTable(self, filenames):\n",
    "        num_train_file=int(self.train_ratio*len(filenames))\n",
    "        for filename in filenames:\n",
    "            sentences=self.getSentences(filename)\n",
    "            for sentence in sentences:\n",
    "                poses=self.extractPos(sentence)\n",
    "                if num_train_file<=0:\n",
    "                    self.test_data.append(poses)\n",
    "                    continue\n",
    "                else:\n",
    "                    self.train_data.append(poses)\n",
    "                for word, pos in poses:\n",
    "                    if not word in self.wordCount:\n",
    "                        self.wordCount[word]=1\n",
    "                    else:\n",
    "                        self.wordCount[word]+=1\n",
    "                    if not pos in self.pos2idx:\n",
    "                        self.pos2idx[pos]=len(self.idx2pos)\n",
    "                        self.idx2pos.append(pos)\n",
    "            num_train_file-=1\n",
    "            \n",
    "        for word in self.wordCount:\n",
    "            count = self.wordCount[word]\n",
    "            if count==1:\n",
    "                continue\n",
    "            self.word2idx[word]=len(self.idx2word)\n",
    "            self.idx2word.append(word)\n",
    "        self.prob_pos2pos=np.zeros([len(self.idx2pos), len(self.idx2pos)])\n",
    "        self.prob_pos2word=np.zeros([len(self.idx2word), len(self.idx2word)])\n",
    "                \n",
    "    def extractPos(self, sentence):\n",
    "        poses=[]\n",
    "        words=sentence.split(' ')\n",
    "        words=[w for w in words if not w=='']\n",
    "        for word in words:\n",
    "            if not '/' in word:\n",
    "                continue\n",
    "            i=-1\n",
    "            while word[i]!='/':\n",
    "                i-=1\n",
    "            pos=word[i+1:]\n",
    "            w=word[:i].lower()\n",
    "            w=self.convertIfFloat(w)\n",
    "            poses.append((w,pos))\n",
    "        return poses\n",
    "            \n",
    "    def convertIfFloat(self,w):\n",
    "        try:\n",
    "            tmp=float(w)\n",
    "            w='NUM'\n",
    "        except:\n",
    "            assert(1==1)\n",
    "        return w\n",
    "    \n",
    "    def convertIfUNK(self, word):\n",
    "        if not word in self.idx2word:\n",
    "            w='UNK'\n",
    "        else:\n",
    "            w=word\n",
    "        return w\n",
    "    \n",
    "    def train(self):\n",
    "        print(f\"Training with {str(len(self.train_data))} sentences.\")\n",
    "        start_time=time.time()\n",
    "        for poses in self.train_data:\n",
    "            prev_pos='BOS'\n",
    "            for word, cur_pos in poses:\n",
    "                w=self.convertIfUNK(word)\n",
    "                self.prob_pos2pos[self.pos2idx[prev_pos]][self.pos2idx[cur_pos]]+=1\n",
    "                self.prob_pos2word[self.pos2idx[cur_pos]][self.word2idx[w]]+=1\n",
    "                prev_pos=cur_pos\n",
    "\n",
    "        \n",
    "        a=self.prob_pos2pos\n",
    "        self.prob_pos2pos=a/(np.sum(a, axis=1).reshape((a.shape[0],1))+1e-15)\n",
    "        a=self.prob_pos2word\n",
    "        self.prob_pos2word=a/(np.sum(a, axis=1).reshape((a.shape[0],1))+1e-15)\n",
    "        elapsed_time=time.time()-start_time\n",
    "        print(f\"Elapsed time {str(elapsed_time)}s\")\n",
    "        \n",
    "    def test(self):\n",
    "        print(f\"Testing with {str(len(self.test_data))} sentences.\")\n",
    "        num_correct=0\n",
    "        num_pos_correct=0\n",
    "        num_pos=0\n",
    "        avg_correct_perc=0\n",
    "        for poses in self.test_data:\n",
    "            sentence=[]\n",
    "            target=[]\n",
    "            for word, pos in poses:\n",
    "                sentence.append(word)\n",
    "                target.append(pos)\n",
    "                num_pos+=1\n",
    "            pred, _ =self.predict(sentence)\n",
    "            if ''.join(pred)==''.join(target):\n",
    "                num_correct+=1\n",
    "            assert(len(pred)==len(target))\n",
    "            correct_cnt=0\n",
    "            for i in range(len(pred)):\n",
    "                if pred[i]==target[i]:\n",
    "                    correct_cnt+=1\n",
    "            num_pos_correct+=correct_cnt\n",
    "            avg_correct_perc+=correct_cnt/len(pred)\n",
    "        avg_correct_perc/=len(self.test_data)\n",
    "        res = {'sentence_acc': num_correct/len(self.test_data), \n",
    "               'pos_acc': num_pos_correct/num_pos, \n",
    "               'avg_cor_perc': avg_correct_perc}\n",
    "        print(f\"Accuracy by sentence ={res['sentence_acc']}\\nAccuracy by word ={res['pos_acc']}\")\n",
    "        print(f\"Average correct prediction ratio per sentence ={res['avg_cor_perc']}\")\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        prev_pos='BOS'\n",
    "        pred=[]\n",
    "        likelihood=1.0\n",
    "        for word in sentence:\n",
    "            mx=-1\n",
    "            mx_pos=''\n",
    "            w=self.convertIfUNK(word)\n",
    "            word_idx=self.word2idx[w]\n",
    "            for pos in self.pos2idx:\n",
    "                cur_pos_idx=self.pos2idx[pos]\n",
    "                a=self.prob_pos2pos[self.pos2idx[prev_pos]][cur_pos_idx]\n",
    "                b=self.prob_pos2word[cur_pos_idx][word_idx]\n",
    "                prob=a*b\n",
    "                if mx<prob:\n",
    "                    mx=prob\n",
    "                    mx_pos=pos\n",
    "            pred.append(mx_pos)\n",
    "            prev_pos=mx_pos\n",
    "            likelihood*=mx\n",
    "        return pred, likelihood\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "filenames=['./treebank/tagged/wsj_'+str(i).zfill(4)+'.pos' for i in range(1,200)]\n",
    "V = Viterbi_PennTree(filenames=filenames,train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1460 sentences.\n",
      "Elapsed time 1.721384048461914s\n"
     ]
    }
   ],
   "source": [
    "V.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 273 sentences.\n",
      "Accuracy by sentence =0.06593406593406594\n",
      "Accuracy by word =0.8646827624929815\n",
      "Average correct prediction ratio per sentence =0.870243114320104\n"
     ]
    }
   ],
   "source": [
    "res=V.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence:\n",
      "-- dorothy l. sayers , `` the nine tailors '' aslacton , england -- of all scenes that evoke rural england , this is one of the loveliest : an ancient stone church stands amid the fields , the sound of bells cascading from its tower , calling the faithful to evensong . \n",
      "\n",
      "Labeled:\n",
      ": NNP NNP NNP , `` DT CD NNP '' NNP , NNP : IN DT NNS WDT VBP JJ NNP , DT VBZ CD IN DT JJS : DT JJ NN NN VBZ IN DT NNS , DT NN IN NNS VBG IN PRP$ NN , VBG DT NN TO NN . \n",
      "\n",
      "Prediction:\n",
      ": NNP NNP NNP , `` DT CD NN '' NNP , NNP : IN DT NN IN NNP NNP NNP , DT VBZ CD IN DT NN : DT NN NN NN VBZ VBN DT NNS , DT JJ IN NNP NNP IN PRP$ NNP , NNP DT NN TO VB . \n",
      "\n",
      "Likelihood=6.500328067697114e-114\n"
     ]
    }
   ],
   "source": [
    "test_data=V.test_data\n",
    "random.shuffle(test_data)\n",
    "sample_sentence=test_data[0]\n",
    "sentence=[w for w,_ in sample_sentence]\n",
    "print(\"Example sentence:\")\n",
    "print(''.join([w+' ' for w,_ in sample_sentence]))\n",
    "print(\"\\nLabeled:\")\n",
    "print(''.join([pos+' ' for _,pos in sample_sentence]))\n",
    "pred, likelihood = V.predict(sentence)\n",
    "print(\"\\nPrediction:\")\n",
    "print(''.join([p+' ' for p in pred]))\n",
    "print(f\"\\nLikelihood={likelihood}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
